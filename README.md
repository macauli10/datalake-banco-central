# ğŸ“Š Projeto de Engenharia de Dados: Pipeline de Reservas Internacionais com Data Lake, Streamlit e Docker

Este projeto foi desenvolvido com o objetivo de simular um pipeline de **engenharia de dados completo**, desde a **extraÃ§Ã£o de dados brutos** de uma API pÃºblica, atÃ© o **armazenamento em Data Lake**, **transformaÃ§Ã£o**, e **visualizaÃ§Ã£o interativa** com Streamlit â€” tudo isso **containerizado com Docker**, para garantir portabilidade e reprodutibilidade do ambiente.

---

## ğŸš€ Tecnologias Utilizadas

- **Python 3.12**
- **Pandas**
- **Streamlit**
- **Docker**
- **API do Banco Central do Brasil (SGS)**
- **Data Lake (Raw e Processed Zones em arquivos)**
- **CSV e JSON**

---

## ğŸ§± Arquitetura do Projeto

```plaintext
datalake-bancocentral/
â”œâ”€â”€ lake/
â”‚   â”œâ”€â”€ raw/               â† Dados brutos (JSON da API)
â”‚   â””â”€â”€ processed/         â† Dados tratados (CSV)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py             â† Script de extraÃ§Ã£o e transformaÃ§Ã£o
â”‚   â””â”€â”€ dashboard.py       â† AplicaÃ§Ã£o Streamlit
â”œâ”€â”€ Dockerfile             â† Docker para empacotar o projeto
â”œâ”€â”€ .dockerignore          â† Ignora arquivos desnecessÃ¡rios
â””â”€â”€ README.md              â† DocumentaÃ§Ã£o
ğŸ› ï¸ Funcionalidades
1. ğŸ“¡ ExtraÃ§Ã£o da API
Os dados sÃ£o extraÃ­dos da API pÃºblica do Banco Central do Brasil (SGS) â€” mais especificamente da sÃ©rie histÃ³rica SGS 1783, que representa as reservas internacionais do Brasil em dÃ³lares.

python
Copy
Edit
https://api.bcb.gov.br/dados/serie/bcdata.sgs.1783/dados?formato=json
2. ğŸ§Š Armazenamento em Data Lake (Raw Zone)
ApÃ³s a extraÃ§Ã£o, os dados sÃ£o armazenados em arquivos JSON na pasta lake/raw/, mantendo o formato original e o histÃ³rico diÃ¡rio.

3. ğŸ” Processed Zone (TransformaÃ§Ã£o)
O script converte os dados brutos para CSV, trata tipos de dados e armazena na pasta lake/processed/, criando uma camada de dados estruturados pronta para anÃ¡lise.

4. ğŸ“ˆ VisualizaÃ§Ã£o com Streamlit
A aplicaÃ§Ã£o dashboard.py consome o CSV da Processed Zone e exibe:

Uma tabela com os dados formatados

Um grÃ¡fico de linha com a evoluÃ§Ã£o temporal das reservas

5. ğŸ³ DockerizaÃ§Ã£o Completa
O projeto Ã© totalmente containerizado. Com Docker instalado, vocÃª pode rodÃ¡-lo em qualquer mÃ¡quina com os comandos:

bash
Copy
Edit
docker build -t dashboard-bcb .
docker run -p 8501:8501 dashboard-bcb
Acesse em: http://localhost:8501

ğŸ“¦ Como Executar Localmente (sem Docker)
Clone o projeto:

bash
Copy
Edit
git clone https://github.com/macauli10/datalake-banco-central.git
cd datalake-bancocentral
Crie um ambiente virtual:

bash
Copy
Edit
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
.venv\Scripts\activate     # Windows
Instale as dependÃªncias:

bash
Copy
Edit
pip install -r requirements.txt
Rode o pipeline:

bash
Copy
Edit
python src/app.py
Inicie o dashboard:

bash
Copy
Edit
streamlit run src/dashboard.py
ğŸ“Œ ConclusÃ£o
Este projeto demonstra um ciclo completo de engenharia de dados:

ExtraÃ§Ã£o automatizada de dados financeiros reais

Armazenamento em camadas de um Data Lake

TransformaÃ§Ã£o estruturada dos dados

VisualizaÃ§Ã£o interativa e acessÃ­vel

Empacotamento com Docker para rodar em qualquer ambiente

Ele serve como base para projetos maiores de dados, podendo ser integrado com bancos relacionais, Airflow, nuvem (AWS S3, GCS), ou ferramentas de modelagem e machine learning.